<!DOCTYPE html> <html lang="en, bg, de"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="3m9Oob5fw7DxBVE7aIi63DaBCHjNFPeluUH9jCmmMBA"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> When t-Tests Fail in A/B Testing | Kaloyan P. Parvanov </title> <meta name="author" content="Kaloyan P. Parvanov"> <meta name="description" content="Why standard t-tests break down with skewed data and how bootstrap methods and concentration inequalities provide reliable alternatives for A/B testing."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.css" integrity="sha256-uRX+PiRTR4ysKFRCykT8HLuRCub26LgXJZym3Yeom1c=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/Favicon2.png?7d25c01b23eb8ef730d6b6ad8c347aaa"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://www.kparvanov.com/blog/2025/ab_testing/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Kaloyan</span> P. Parvanov </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">When t-Tests Fail in A/B Testing</h1> <p class="post-meta"> Created in July 06, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/a-b-testing"> <i class="fa-solid fa-hashtag fa-sm"></i> a/b testing</a>   <a href="/blog/tag/bootstrap"> <i class="fa-solid fa-hashtag fa-sm"></i> bootstrap</a>   <a href="/blog/tag/concentration-inequalities"> <i class="fa-solid fa-hashtag fa-sm"></i> concentration inequalities</a>   ·   <a href="/blog/category/statistics"> <i class="fa-solid fa-tag fa-sm"></i> statistics</a>   <a href="/blog/category/data-science"> <i class="fa-solid fa-tag fa-sm"></i> data science</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>A/B testing failures in production often share common mathematical roots. An experiment on revenue can look transformative when a single “whale” user makes a large purchase, only for the result to lose significance as more data arrives.</p> <p>The standard t-test framework assumes your data is independent and normally distributed. At a massive scale with tens of thousands of users, these assumptions often hold well enough due to the Central Limit Theorem (CLT). But for many companies, especially startups, that scale is an unaffordable luxury. They may not have access to enough users or cannot afford to run experiments long enough to gather the massive samples needed to blindly trust the t-test.</p> <p>At these more moderate sample sizes, reality is messier. This is because business metrics are often plagued by issues like:</p> <ul> <li> <strong>Skewed Distributions:</strong> Unlike height or weight, metrics like revenue are not symmetric; most users spend little, while a few spend a lot.</li> <li> <strong>Extreme Outliers:</strong> The presence of “whale” users can dramatically pull the average, destabilizing the results.</li> <li> <strong>Clustered Behavior:</strong> Users do not act independently. A single user can have multiple sessions, violating the i.i.d. (independent and identically distributed) assumption.</li> </ul> <p>The solution is not to abandon t-tests entirely, but to know when their assumptions break down and to have robust alternatives ready.</p> <h2 id="why-welchs-t-test-falters">Why Welch’s t-Test Falters</h2> <p>Most A/B testing platforms default to Welch’s t-test, an adaptation of the Student’s t-test that does not assume equal variances between groups. It relies on the test statistic converging to a normal distribution.</p> \[\frac{(\bar{X}_T - \bar{X}_C) - (\mu_T - \mu_C)}{\sqrt{\frac{s_T^2}{n_T} + \frac{s_C^2}{n_C}}} \xrightarrow{d} \mathcal{N}(0,1)\] <p>This convergence requires three conditions: <strong>independent observations</strong>, <strong>finite variance</strong>, and a <strong>sufficiently large sample size</strong> for the CLT to take effect. When these assumptions crumble, you need methods designed for chaos, not textbook perfection.</p> <details> <summary>Click to see the t-test implementation</summary> <pre><code class="language-python">import numpy as np
import warnings
from scipy import stats

def ttest_ab_test(control_data, treatment_data, alpha=0.05):
    """Performs a Welch's t-test for A/B testing."""
    n_c, n_t = len(control_data), len(treatment_data)
    mean_c, mean_t = np.mean(control_data), np.mean(treatment_data)
    var_c, var_t = np.var(control_data, ddof=1), np.var(treatment_data, ddof=1)

    diff_mean = mean_t - mean_c
    pooled_se = np.sqrt(var_c / n_c + var_t / n_t)
    if pooled_se == 0:
        return {'significant': False, 'p_value': 1.0, 'difference': diff_mean, 'ci_lower': diff_mean, 'ci_upper': diff_mean}

    t_stat = diff_mean / pooled_se
    df = (var_c / n_c + var_t / n_t)**2 / ((var_c / n_c)**2 / (n_c - 1) + (var_t / n_t)**2 / (n_t - 1))
    p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))
    margin = stats.t.ppf(1 - alpha / 2, df) * pooled_se

    return {
        'difference': diff_mean,
        'ci_lower': diff_mean - margin,
        'ci_upper': diff_mean + margin,
        'significant': p_value &lt; alpha,
        'p_value': p_value
    }
</code></pre> </details> <h2 id="bootstrap-methods-for-distribution-free-inference">Bootstrap Methods for Distribution-Free Inference</h2> <p>The bootstrap, introduced by Efron in 1979, addresses a core limitation of the t-test. Instead of assuming normality, the bootstrap estimates the sampling distribution empirically by resampling from the observed data. The core principle is simple: if the sample approximates the population, then resampling from the sample approximates sampling from the population.</p> <h3 id="bias-corrected-and-accelerated-bca-bootstrap">Bias-Corrected and Accelerated (BCa) Bootstrap</h3> <p>The Bias-Corrected and Accelerated (BCa) bootstrap is an advanced method that adjusts the confidence interval to account for both <strong>bias</strong> and <strong>skewness</strong> in the bootstrap distribution. It calculates adjusted percentile points (\(\alpha_1, \alpha_2\)) to provide a more accurate interval.</p> <p>The adjustments are based on two parameters: a <strong>bias-correction factor</strong> (\(\hat{z}_0\)) and an <strong>acceleration parameter</strong> (\(\hat{a}\)).</p> \[\hat{z}_0 = \Phi^{-1}\left( \frac{\#\{\hat{\theta}^*_b &lt; \hat{\theta}\}}{B} \right)\] <p>Where:</p> <ul> <li> <strong>\(\hat{\theta}\)</strong> (theta-hat) is the statistic calculated from the original data (e.g., the observed difference in means).</li> <li> <strong>\(B\)</strong> is the total number of bootstrap samples generated.</li> <li> <strong>\(\hat{\theta}^*_b\)</strong> is the same statistic calculated for the <em>b-th</em> bootstrap sample. The fraction inside the formula simply represents the proportion of bootstrap statistics that were less than the original statistic.</li> </ul> <p>The acceleration parameter \(\hat{a}\) is calculated using jackknife resampling.</p> \[\hat{a} = \frac{\sum_{i=1}^n (\bar{\theta} - \theta_{(i)})^3}{6\left[\sum_{i=1}^n (\bar{\theta} - \theta_{(i)})^2\right]^{3/2}}\] <p>Where:</p> <ul> <li> <strong>\(\theta_{(i)}\)</strong> is the “jackknife” estimate, meaning the same statistic calculated on the original data but with the <em>i-th</em> observation removed.</li> <li> <strong>\(\bar{\theta}\)</strong> is the average of all the jackknife estimates, \(\frac{1}{n}\sum_{i=1}^n \theta_{(i)}\).</li> </ul> <p>These two parameters are then used to find the adjusted percentile levels for the confidence interval.</p> \[\alpha_1 = \Phi\left( \hat{z}_0 + \frac{\hat{z}_0 + z_{\alpha/2}}{1 - \hat{a}(\hat{z}_0 + z_{\alpha/2})} \right) \quad \text{and} \quad \alpha_2 = \Phi\left( \hat{z}_0 + \frac{\hat{z}_0 + z_{1-\alpha/2}}{1 - \hat{a}(\hat{z}_0 + z_{1-\alpha/2})} \right)\] <p>While the math is involved, the takeaway is simple. BCa provides a data-driven way to correct for imperfections that a standard bootstrap ignores.</p> <p>Note that the jackknife step for the acceleration parameter can be computationally expensive (O(n²)). For production use on samples larger than a few thousand, consider using optimized libraries like <code class="language-plaintext highlighter-rouge">scipy.bootstrap</code>. For very large datasets, you can also use the fast approximation for \(\hat{a}\) found in Efron &amp; Tibshirani (1994).</p> <details> <summary>Click to see the BCa bootstrap implementation</summary> <pre><code class="language-python">def bca_ab_test(control_data, treatment_data, alpha=0.05, n_bootstrap=2000):
    """Performs a BCa bootstrap for the difference in means."""
    rng = np.random.default_rng()
    n_c, n_t = len(control_data), len(treatment_data)
    observed_diff = np.mean(treatment_data) - np.mean(control_data)

    bootstrap_diffs = []
    for _ in range(n_bootstrap):
        boot_control = rng.choice(control_data, size=n_c, replace=True)
        boot_treatment = rng.choice(treatment_data, size=n_t, replace=True)
        bootstrap_diffs.append(np.mean(boot_treatment) - np.mean(boot_control))
    bootstrap_diffs = np.array(bootstrap_diffs)

    prop_less = np.mean(bootstrap_diffs &lt; observed_diff)
    if prop_less == 0 or prop_less == 1:
        ci_lower = np.percentile(bootstrap_diffs, 100 * alpha/2)
        ci_upper = np.percentile(bootstrap_diffs, 100 * (1-alpha/2))
        return {'difference': observed_diff, 'ci_lower': ci_lower, 'ci_upper': ci_upper, 'significant': (ci_lower &gt; 0) or (ci_upper &lt; 0)}

    z_0 = stats.norm.ppf(prop_less)

    combined_data = np.concatenate([control_data, treatment_data])
    n_total = len(combined_data)
    jackknife_stats = []
    for i in range(n_total):
        jk_sample = np.delete(combined_data, i)
        if i &lt; n_c:
            jk_control = jk_sample[:n_c-1]
            jk_treatment = jk_sample[n_c-1:]
        else:
            jk_control = jk_sample[:n_c]
            jk_treatment = jk_sample[n_c:]
        jackknife_stats.append(np.mean(jk_treatment) - np.mean(jk_control))
    jackknife_stats = np.array(jackknife_stats)
    jk_mean = np.mean(jackknife_stats)
    
    numerator = np.sum((jk_mean - jackknife_stats)**3)
    denominator = 6 * (np.sum((jk_mean - jackknife_stats)**2))**1.5
    if denominator == 0:
        ci_lower = np.percentile(bootstrap_diffs, 100 * alpha/2)
        ci_upper = np.percentile(bootstrap_diffs, 100 * (1-alpha/2))
        return {'difference': observed_diff, 'ci_lower': ci_lower, 'ci_upper': ci_upper, 'significant': (ci_lower &gt; 0) or (ci_upper &lt; 0)}

    a_hat = numerator / denominator

    z_alpha = stats.norm.ppf([alpha / 2, 1 - alpha / 2])
    z_term = z_0 + z_alpha
    alpha_adj_num = z_0 + z_term / (1 - a_hat * z_term)
    alpha_adj = stats.norm.cdf(alpha_adj_num)

    ci_lower = np.percentile(bootstrap_diffs, 100 * alpha_adj[0])
    ci_upper = np.percentile(bootstrap_diffs, 100 * alpha_adj[1])

    return {
        'difference': observed_diff,
        'ci_lower': ci_lower,
        'ci_upper': ci_upper,
        'significant': (ci_lower &gt; 0) or (ci_upper &lt; 0)
    }
</code></pre> </details> <h2 id="concentration-inequalities-for-heavy-tailed-data">Concentration Inequalities for Heavy-Tailed Data</h2> <p>When data is extremely heavy-tailed or sample sizes are small, even the bootstrap can be unreliable. <strong>Concentration inequalities</strong> provide a powerful, non-asymptotic alternative. They give explicit, finite-sample bounds on how much a sample mean can deviate from its true mean, without making distributional assumptions.</p> <h3 id="a-deeper-look-at-sub-exponential-variables">A Deeper Look at Sub-Exponential Variables</h3> <p>Many metrics are <strong>sub-exponential</strong>, meaning their tails decay at least as fast as an exponential distribution. For a sum of such variables, <strong>Bernstein’s inequality</strong> provides a tight bound on the deviation of the sample mean \(\bar{X}\) from the true mean \(\mu\).</p> \[\mathbb{P}\left( \left|\bar{X} - \mu\right| \geq t \right) \leq 2\exp\left( -\frac{nt^2}{2v^2 + 2bt} \right)\] <p>The term \(v^2\) acts like a variance parameter, while \(b\) controls for the heavy tail.</p> <h3 id="the-practical-challenge-and-solution">The Practical Challenge and Solution</h3> <p>In practice, estimating the tail parameter \(b\) from data is difficult and often not robust. However, for a wide range of problems, we can use a simpler and more robust <strong>empirical Bernstein bound</strong>.</p> <p>This approach relies on the sample variance \(s^2\) (assuming independent observations) to estimate \(v^2\) and gracefully handles the tail term. For the difference between two means, this simplifies to the following confidence interval calculation.¹</p> \[CI = (\bar{X}_T - \bar{X}_C) \pm \sqrt{\left(\frac{s_C^2}{n_C} + \frac{s_T^2}{n_T}\right) 2 \log(2/\alpha)}\] <p>This formula provides a robust, conservative confidence interval with guaranteed coverage, making it ideal for high-stakes decisions or noisy data.</p> <hr> <p>¹ <em>Some variations of this bound use a slightly different constant, such as</em> \(\log(3/\alpha)\). <em>The</em> \(\log(2/\alpha)\) <em>form is a common and intuitive choice.</em></p> <details> <summary>Click to see the concentration inequality implementation</summary> <pre><code class="language-python">def concentration_ab_test(control_data, treatment_data, alpha=0.05):
    """Constructs a CI for the difference in means via a concentration inequality."""
    n_c, n_t = len(control_data), len(treatment_data)
    mean_c, mean_t = np.mean(control_data), np.mean(treatment_data)
    var_c, var_t = np.var(control_data, ddof=1), np.var(treatment_data, ddof=1)
    
    diff_mean = mean_t - mean_c
    diff_var = var_c / n_c + var_t / n_t
    epsilon = np.sqrt(2 * diff_var * np.log(2 / alpha))
    
    return {
        'difference': diff_mean,
        'ci_lower': diff_mean - epsilon,
        'ci_upper': diff_mean + epsilon,
        'significant': (diff_mean - epsilon &gt; 0) or (diff_mean + epsilon &lt; 0)
    }
</code></pre> </details> <h2 id="practical-implementation">Practical Implementation</h2> <p>Here is a unified function that automatically selects a method based on data characteristics. The key diagnostic is the <strong>coefficient of variation (CV)</strong>, which measures relative variability. Revenue metrics often have a CV greater than 2.</p> <details> <summary>Click to see the unified robust A/B test implementation</summary> <pre><code class="language-python">def robust_ab_test(control_data, treatment_data, alpha=0.05, method='auto'):
    """Selects an A/B test based on the data's coefficient of variation."""
    n_c, n_t = len(control_data), len(treatment_data)
    mean_c, mean_t = np.mean(control_data), np.mean(treatment_data)
    std_c, std_t = np.std(control_data, ddof=1), np.std(treatment_data, ddof=1)
    
    cv_c = std_c / mean_c if mean_c &gt; 0 else float('inf')
    cv_t = std_t / mean_t if mean_t &gt; 0 else float('inf')
    max_cv = max(cv_c, cv_t)
    
    if method == 'auto':
        if max_cv &lt; 1.5 and min(n_c, n_t) &gt; 500:
            method = 'ttest'
        elif max_cv &gt; 2.5:
            method = 'concentration'
        else:
            method = 'bootstrap'
    
    if method == 'ttest':
        result = ttest_ab_test(control_data, treatment_data, alpha)
    elif method == 'bootstrap':
        result = bca_ab_test(control_data, treatment_data, alpha, n_bootstrap=5000)
    elif method == 'concentration':
        result = concentration_ab_test(control_data, treatment_data, alpha)
    else:
        raise ValueError(f"Unknown method: {method}")
    
    result['method'] = method
    result['cv_control'] = cv_c
    result['cv_treatment'] = cv_t
    return result
</code></pre> </details> <h2 id="method-selection-guidelines">Method Selection Guidelines</h2> <p>A method-selection cheat-sheet for experimenters (Table 1).</p> <table> <thead> <tr> <th style="text-align: left">Data Characteristics</th> <th style="text-align: left">Recommended Method</th> <th style="text-align: left">Reason</th> </tr> </thead> <tbody> <tr> <td style="text-align: left"> <strong>CV &lt; 1.5</strong>, n &gt; 500, few outliers</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">t-test</code></td> <td style="text-align: left">Classical assumptions hold reasonably well.</td> </tr> <tr> <td style="text-align: left"> <strong>CV &gt; 2.5</strong> or very heavy tails</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">concentration</code></td> <td style="text-align: left">Provides robust, guaranteed bounds for wild data.</td> </tr> <tr> <td style="text-align: left">Moderate skewness/outliers</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">bootstrap</code></td> <td style="text-align: left">Handles skewness well without distributional assumptions.</td> </tr> <tr> <td style="text-align: left">Small samples (n &lt; 500)</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">concentration</code></td> <td style="text-align: left">Offers strong finite-sample guarantees.</td> </tr> </tbody> </table> <h2 id="worked-example-with-heavy-tailed-revenue-data">Worked Example with Heavy-Tailed Revenue Data</h2> <p>Let’s simulate a revenue test where data follows a Pareto distribution, commonly used to model wealth distribution and user spending patterns where a few “power users” contribute disproportionately.</p> <details> <summary>Click to see the simulation and analysis code</summary> <pre><code class="language-python">print("=== A/B Testing with Pareto Distribution ===")

rng = np.random.default_rng(seed=475)

control_revenue = rng.pareto(1.8, 150)
treatment_revenue = rng.pareto(1.8, 150)

with warnings.catch_warnings():
    warnings.simplefilter("ignore")
    result = robust_ab_test(control_revenue, treatment_revenue)

print(f"Method automatically selected: {result['method'].title()}")
print(f"Control CV: {result['cv_control']:.2f}, Treatment CV: {result['cv_treatment']:.2f}")
print(f"Observed Difference: ${result['difference']:.2f}")
print(f"95% CI: [${result['ci_lower']:.2f}, ${result['ci_upper']:.2f}]")
print(f"Significant: {result['significant']}")

print("\n=== Method Comparison ===")
with warnings.catch_warnings():
    warnings.simplefilter("ignore")
    ttest_result = ttest_ab_test(control_revenue, treatment_revenue)
    bootstrap_result = bca_ab_test(control_revenue, treatment_revenue, n_bootstrap=5000)
    concentration_result = concentration_ab_test(control_revenue, treatment_revenue)

print(f"T-test:        Diff=${ttest_result['difference']:.2f}, CI=[${ttest_result['ci_lower']:.2f}, ${ttest_result['ci_upper']:.2f}], Sig={ttest_result['significant']}")
print(f"Bootstrap:     Diff=${bootstrap_result['difference']:.2f}, CI=[${bootstrap_result['ci_lower']:.2f}, ${bootstrap_result['ci_upper']:.2f}], Sig={bootstrap_result['significant']}")
print(f"Concentration: Diff=${concentration_result['difference']:.2f}, CI=[${concentration_result['ci_lower']:.2f}, ${concentration_result['ci_upper']:.2f}], Sig={concentration_result['significant']}")
</code></pre> </details> <p><strong>Example Output</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>=== A/B Testing with Pareto Distribution ===
Method automatically selected: Bootstrap
Control CV: 2.13, Treatment CV: 1.42
Observed Difference: $0.42
95% CI: [$-0.06, $0.79]
Significant: False

=== Method Comparison ===
T-test:        Diff=$0.42, CI=[$0.01, $0.83], Sig=True
Bootstrap:     Diff=$0.42, CI=[$-0.02, $0.80], Sig=False
Concentration: Diff=$0.42, CI=[$-0.14, $0.99], Sig=False
</code></pre></div></div> <p>The <code class="language-plaintext highlighter-rouge">robust_ab_test</code> function correctly identifies moderate skewness (control CV = 2.13) and automatically selects the bootstrap method. This example demonstrates a crucial difference: the t-test incorrectly claims significance with CI = [$0.01, $0.83], while both robust methods (bootstrap and concentration) correctly identify that the difference is not statistically significant. This is exactly the type of false positive that can lead to misguided business decisions when relying solely on t-tests with skewed data.</p> <h3 id="key-takeaways">Key Takeaways</h3> <ol> <li> <strong>T-tests Are Brittle.</strong> The assumptions of the t-test (like normally distributed data) are often violated by real-world business metrics like revenue, which are typically skewed and filled with outliers.</li> <li> <strong>This Fragility Leads to Costly Errors.</strong> A “significant” p-value from a t-test can be a statistical mirage. As the article’s final example shows, random outliers can easily trick a t-test into declaring a false positive, which can lead to misguided business decisions.</li> <li> <strong>Robust Methods Provide a More Honest Picture.</strong> Techniques like the bootstrap don’t assume your data is clean. They are designed to correctly identify the massive uncertainty caused by outliers, providing a crucial safeguard against being misled.</li> <li> <strong>Your Choice of Statistical Tool Is a Business Decision.</strong> The difference between a t-test and a bootstrap on the same messy dataset can be the difference between a confident but wrong product launch and a correctly cautious one.</li> </ol> <h2 id="references">References</h2> <ul> <li>Boucheron, S., Lugosi, G., &amp; Massart, P. (2013). <em>Concentration Inequalities: A Nonasymptotic Theory of Independence</em>. Oxford University Press.</li> <li>DiCiccio, T. J., &amp; Efron, B. (1996). Bootstrap Confidence Intervals. <em>Statistical Science</em>, 11(3), 189-228.</li> <li>Efron, B. (1979). Bootstrap Methods: Another Look at the Jackknife. <em>The Annals of Statistics</em>, 7(1), 1-26.</li> <li>Efron, B., &amp; Tibshirani, R. J. (1994). <em>An Introduction to the Bootstrap</em>. Chapman &amp; Hall/CRC.</li> </ul> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Kaloyan P. Parvanov. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: July 06, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.js" integrity="sha256-4rppopQE9POKfukn2kEvhJ9Um25Cf6+IDVkARD0xh78=" crossorigin="anonymous"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-D9ELQTS46J"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-D9ELQTS46J");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"Blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"Projects",description:"This is a collection of most of the projects I have worked on so far in my career.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-cv",title:"CV",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-when-t-tests-fail-in-a-b-testing",title:"When t-Tests Fail in A/B Testing",description:"Why standard t-tests break down with skewed data and how bootstrap methods and concentration inequalities provide reliable alternatives for A/B testing.",section:"Posts",handler:()=>{window.location.href="/blog/2025/ab_testing/"}},{id:"post-the-st-petersburg-paradox-re-run-over-time",title:"The St. Petersburg Paradox, Re-Run Over Time",description:"How an old paradox reveals a deep flaw in classical economics and points the way to a more realistic model of human decision-making.",section:"Posts",handler:()=>{window.location.href="/blog/2025/st_petersburg/"}},{id:"post-the-button-game-when-should-you-stop-for-the-best-prize",title:"The Button Game: When Should You Stop for the Best Prize?",description:"An interesting interview question about optimal stopping.",section:"Posts",handler:()=>{window.location.href="/blog/2025/button_game/"}},{id:"post-detecting-regime-shifts-in-sp500-stocks-using-pca-and-sparse-pca",title:"Detecting Regime Shifts in SP500 Stocks Using PCA and Sparse PCA",description:"This project explores PCA and Sparse PCA on 457 SP500 stocks, using 2-minute interval data over 31 trading days (August 8 to September 19, 2024). The focus is on experimenting with dimensionality reduction techniques to identify regime shifts and key factors driving stock returns.",section:"Posts",handler:()=>{window.location.href="/blog/2024/distill/"}},{id:"post-the-damped-unforced-pendulum-problem",title:"The Damped Unforced Pendulum Problem",description:"Applying physics-informed neural networks to ODEs",section:"Posts",handler:()=>{window.location.href="/blog/2023/distill/"}},{id:"projects-physics-informed-neural-networks",title:"Physics-Informed Neural Networks",description:"Solving the unforced damped pendulum problem",section:"Projects",handler:()=>{window.location.href="/projects/PINN_project/"}},{id:"projects-regimeshift",title:"RegimeShift",description:"PCA Analysis of the SP500 Stocks",section:"Projects",handler:()=>{window.location.href="/projects/RegimeShift/"}},{id:"projects-eagle-eye",title:"Eagle Eye",description:"AI-Powered Search Engine",section:"Projects",handler:()=>{window.location.href="/projects/eagle_eye_project/"}},{id:"projects-gmail-smart-labeler",title:"GMail Smart Labeler",description:"AI-Powered Email Labeler",section:"Projects",handler:()=>{window.location.href="/projects/gmail_smart_labeler/"}},{id:"projects-mathbuddy",title:"MathBuddy",description:"AI-Powered Math Tutor",section:"Projects",handler:()=>{window.location.href="/projects/mathbuddy_project/"}},{id:"projects-tic-tac-toe",title:"Tic Tac Toe",description:"Tic-Tac-Toe AI with Alpha-Beta Pruning Minimax Algorithm",section:"Projects",handler:()=>{window.location.href="/projects/tic_tac_toe_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%70%61%72%76%61%6E%6F%76%6B%61%6C%6F%79%61%6E@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/parvanovkp","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/kparvanov","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/kparvanov1","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>